function ldaParams = LDAModelMnist(mnistTraining, mnistTesting, ldaParams)
    % What it does: 
    %   Function us a part of the data to train the LDA model, and then use
    %   the rest to validate the model, and then it will predict with the
    %   model on the: Training set, the test set, and the  validation set. 
    % 
    % mnistTraining: 
    %   An instance of the class LDAModelMnist, it has to be a training
    %   instace. 
    % mnistTesting
    %   An instacoe of the class LDAModeMnist, it has to be a testing
    %   instance. 
    % ldaParams: 
    %   An instance f the class LDAParameters. Which is stored for all the
    %   parameters that are relatvent to the training of the model. 
    
    % Get the raining and the testing data. 
    TrainX = mnistTrainig.DataStd; 
    TrainY = mnistTraining.Labels; 
    TestX = mnistTesting.DataStd; 
    TestY = mnistTesting.Labels; 
    
    % Split the labels according to settings. 
    LabelSplit = ldaParams.PlitByLabels; 
    [TrainX, TrainY, ~] = SplitByLabels(TrainX, TrainY, LabelSplit); 
    [TestX, TestY, ~] = SplitByLabels(TestX, TestY); 
    
    % This we have PCA dim reduction option on: 
    PCAOnOff = LdaParams.PCAOnOff; 
    if PCAOnOff 
        [TrainX, TrainY, Projector, ~] = mnistTraining.principalProj(ldaParams.pcaEnergy, LabelSplit); 
        TestX = Projector*TestX; 
    end
    
    % Permutes the data, 90% for training, and 10% for validation. 
    Permvec = randperm(length(TrainY));
    PermvecTrain = Permvec(1: floor(0.9*length(TrainY))); 
    PermvecValidate = Permvec(floor(0.9*length(TrainY)) + 1: end);
    X = TrainX(:, PermvecTrain);
    Y = TrainY(PermvecTrain);
    X1 = TrainX(:, PermvecValidate); 
    Y1 = TrainY(PermvecValidate); 
    
    % Train the model on the 90% of the data and the labels: 
    TrainedModel = fitcdiscr(X.', Y.', "DiscrimType", ideParams.DisType); 
    ldaParams.TrainedModel = TrainedModel; 
    
    % Get the predicted labels on all the trainning set. 
    
    
    % Validate on the validation set, store the results for the
    % validation set. 
    PredictedValidateLabels = predict(TrainedModel, X1.'); 
    ldaParams.PredictedValidateLabels = PredictedValidateLabels;
    ldaParams.CorssValLoss = sum(PredictedValidateLabels ~= reshape(Y1, length(PredictedValidateLabels)))... 
        /length(PredictedValidateLabels); 
    
    % Test on the test set, store the results for the test set. 
    PredictedTestLabels = predict(TrainedModel, TestX.'); 
    
    
    
end

